{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/olyaeeen/Desktop/Ehsan/jupyter/')\n",
    "from utils import *\n",
    "import numpy as np\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import PIL\n",
    "from IPython.display import Image\n",
    "import cv2\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, UpSampling3D, concatenate\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # normal objects\n",
    "# DATA_DIR='/home/olyaeeen/Desktop/Ehsan/data/normal/'\n",
    "# image_list = sorted(glob.glob(DATA_DIR+'*-subvolume-normalized.nii.gz'))[-2:]\n",
    "# gt_list = sorted(glob.glob(DATA_DIR+'*-Segmentation-smoothed-label.nii.gz'))[-2:]\n",
    "\n",
    "#all objects\n",
    "DATA_DIR='/home/olyaeeen/Desktop/Ehsan/data/data_all/'\n",
    "image_list = sorted(glob.glob(DATA_DIR+'*-subvolume-normalized.nii.gz'))\n",
    "gt_list = sorted(glob.glob(DATA_DIR+'*-subvolume-split-label-myo-fixed-tformedBack.nii.gz'))\n",
    "\n",
    "CSV_LOG_DIR = '/home/olyaeeen/Desktop/Ehsan/log/unet_training.log'\n",
    "LOG_DIR = '/home/olyaeeen/Desktop/Ehsan/log/'\n",
    "MODELS_DIR = '/home/olyaeeen/Desktop/Ehsan/models/unet/'\n",
    "if not os.path.exists(MODELS_DIR):\n",
    "    os.makedirs(MODELS_DIR) \n",
    "\n",
    "gt_len = len(gt_list)\n",
    "# print(len(gt_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT_SHAPE = (144, 144, 144)\n",
    "INPUT_SHAPE = (64, 64, 64)\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 1\n",
    "STEP_PER_EPOCH = len(image_list)// BATCH_SIZE\n",
    "CHANNELS_LAST=True\n",
    "SAVE_MODEL_PERIOD = 1\n",
    "\n",
    "tf.keras.backend.set_image_data_format('channels_last' if CHANNELS_LAST is True else 'channels_first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = VolumeDataGenerator(image_list, gt_list, batch_size=BATCH_SIZE, crop=True, dim_crop=INPUT_SHAPE, to_categorical=True, channels_last=CHANNELS_LAST, gt_includes_bg=True)\n",
    "img, gt = next(iter(ds))\n",
    "print(img.shape, gt.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CHANNELS_LAST is True:\n",
    "    visualize_volume(img[0, :, :, :, 0], undo_categorical(gt, channels_last=True), 10)\n",
    "else:\n",
    "    visualize_volume(img[0, 0, :, :, :], undo_categorical(gt, channels_last=False), 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if CHANNELS_LAST is True:\n",
    "#     visualize_volume(img[0, :, :, :, 0], gt[0, :, :, :, 0], 10)\n",
    "# else:\n",
    "#     visualize_volume(img[0, 0, :, :, :], gt[0, 0, :, :, :], 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if CHANNELS_LAST is True:\n",
    "#     gifs = make_gif(img[0, :, :, :, 0], gt[0, :, :, :, 0])\n",
    "# else:\n",
    "#     gifs = make_gif(img[0, 0, :, :, :], gt[0, 0, :, :, :])\n",
    "\n",
    "# # display(gifs[0])\n",
    "# # display(gifs[1])\n",
    "# # display(gifs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class unet(object):\n",
    "\n",
    "    def __init__(self, use_upsampling=False, learning_rate=0.001,\n",
    "                 n_cl_in=1, n_cl_out=1, feature_maps = 16,\n",
    "                 dropout=0.2, print_summary=False,\n",
    "                 channels_last = True):\n",
    "\n",
    "        self.channels_last = channels_last\n",
    "        if channels_last:\n",
    "            self.concat_axis = -1\n",
    "            self.data_format = \"channels_last\"\n",
    "\n",
    "        else:\n",
    "            self.concat_axis = 1\n",
    "            self.data_format = \"channels_first\"\n",
    "\n",
    "        #print(\"Data format = \" + self.data_format)\n",
    "#         K.backend.set_image_data_format(self.data_format)\n",
    "\n",
    "        self.fms = feature_maps # 16 or 32 feature maps in the first convolutional layer\n",
    "\n",
    "        self.use_upsampling = use_upsampling\n",
    "        self.dropout = dropout\n",
    "        self.print_summary = print_summary\n",
    "        self.n_cl_in = n_cl_in\n",
    "        self.n_cl_out = n_cl_out\n",
    "\n",
    "        # self.loss = self.dice_coef_loss\n",
    "        self.loss = self.combined_dice_ce_loss\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.optimizer = keras.optimizers.Adam(lr=self.learning_rate)\n",
    "\n",
    "        self.metrics= [self.dice_coef, self.soft_dice_coef, \"accuracy\",\n",
    "                 self.sensitivity, self.specificity]\n",
    "\n",
    "        self.custom_objects = {\n",
    "            \"combined_dice_ce_loss\": self.combined_dice_ce_loss,\n",
    "            \"dice_coef_loss\": self.dice_coef_loss,\n",
    "            \"dice_coef\": self.dice_coef,\n",
    "            \"soft_dice_coef\": self.soft_dice_coef,\n",
    "            \"sensitivity\": self.sensitivity,\n",
    "            \"specificity\": self.specificity}\n",
    "\n",
    "        self.model = self.unet_3d()\n",
    "\n",
    "    def dice_coef(self, target, prediction, axis=(1, 2, 3), smooth=0.01):\n",
    "        \"\"\"\n",
    "        Sorenson Dice\n",
    "        \\frac{  2 \\times \\left | T \\right | \\cap \\left | P \\right |}{ \\left | T \\right | +  \\left | P \\right |  }\n",
    "        where T is ground truth mask and P is the prediction mask\n",
    "        \"\"\"\n",
    "        prediction = tf.round(prediction)  # Round to 0 or 1\n",
    "\n",
    "        intersection = tf.reduce_sum(target * prediction, axis=axis)\n",
    "        union = tf.reduce_sum(target + prediction, axis=axis)\n",
    "        numerator = tf.constant(2.) * intersection + smooth\n",
    "        denominator = union + smooth\n",
    "        coef = numerator / denominator\n",
    "\n",
    "        return tf.reduce_mean(coef)\n",
    "\n",
    "    def soft_dice_coef(self, target, prediction, axis=(1, 2, 3), smooth=0.01):\n",
    "        \"\"\"\n",
    "        Sorenson (Soft) Dice - Don't round predictions\n",
    "        \\frac{  2 \\times \\left | T \\right | \\cap \\left | P \\right |}{ \\left | T \\right | +  \\left | P \\right |  }\n",
    "        where T is ground truth mask and P is the prediction mask\n",
    "        \"\"\"\n",
    "        intersection = tf.reduce_sum(target * prediction, axis=axis)\n",
    "        union = tf.reduce_sum(target + prediction, axis=axis)\n",
    "        numerator = tf.constant(2.) * intersection + smooth\n",
    "        denominator = union + smooth\n",
    "        coef = numerator / denominator\n",
    "\n",
    "        return tf.reduce_mean(coef)\n",
    "\n",
    "\n",
    "    def dice_coef_loss(self, target, prediction, axis=(1, 2, 3), smooth=0.1):\n",
    "        \"\"\"\n",
    "        Sorenson (Soft) Dice loss\n",
    "        Using -log(Dice) as the loss since it is better behaved.\n",
    "        Also, the log allows avoidance of the division which\n",
    "        can help prevent underflow when the numbers are very small.\n",
    "        \"\"\"\n",
    "        intersection = tf.reduce_sum(prediction * target, axis=axis)\n",
    "        p = tf.reduce_sum(prediction, axis=axis)\n",
    "        t = tf.reduce_sum(target, axis=axis)\n",
    "        numerator = tf.reduce_mean(intersection + smooth)\n",
    "        denominator = tf.reduce_mean(t + p + smooth)\n",
    "        dice_loss = -tf.math.log(2.*numerator) + tf.math.log(denominator)\n",
    "\n",
    "        return dice_loss\n",
    "\n",
    "\n",
    "    def combined_dice_ce_loss(self, target, prediction, axis=(1, 2, 3),\n",
    "                              smooth=0.1, weight=0.7):\n",
    "        \"\"\"\n",
    "        Combined Dice and Binary Cross Entropy Loss\n",
    "        \"\"\"\n",
    "        return weight*self.dice_coef_loss(target, prediction, axis, smooth) + \\\n",
    "            (1-weight)*keras.losses.binary_crossentropy(target, prediction)\n",
    "\n",
    "\n",
    "    def unet_3d(self):\n",
    "        \"\"\"\n",
    "        3D U-Net\n",
    "        \"\"\"\n",
    "        def ConvolutionBlock(x, name, fms, params):\n",
    "            \"\"\"\n",
    "            Convolutional block of layers\n",
    "            Per the original paper this is back to back 3D convs\n",
    "            with batch norm and then ReLU.\n",
    "            \"\"\"\n",
    "\n",
    "            x = keras.layers.Conv3D(filters=fms, **params, name=name+\"_conv0\")(x)\n",
    "            x = keras.layers.BatchNormalization(name=name+\"_bn0\")(x)\n",
    "            x = keras.layers.Activation(\"relu\", name=name+\"_relu0\")(x)\n",
    "\n",
    "            x = keras.layers.Conv3D(filters=fms, **params, name=name+\"_conv1\")(x)\n",
    "            x = keras.layers.BatchNormalization(name=name+\"_bn1\")(x)\n",
    "            x = keras.layers.Activation(\"relu\", name=name)(x)\n",
    "\n",
    "            return x\n",
    "\n",
    "        if self.channels_last:\n",
    "            input_shape = [None, None, None, self.n_cl_in]\n",
    "        else:\n",
    "            input_shape = [self.n_cl_in, None, None, None]\n",
    "\n",
    "        inputs = keras.layers.Input(shape=input_shape,\n",
    "                                name=\"MRImages\")\n",
    "\n",
    "        params = dict(kernel_size=(3, 3, 3), activation=None,\n",
    "                      padding=\"same\", data_format=self.data_format,\n",
    "                      kernel_initializer=\"he_uniform\")\n",
    "\n",
    "        # Transposed convolution parameters\n",
    "        params_trans = dict(data_format=self.data_format,\n",
    "                            kernel_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                            padding=\"same\")\n",
    "\n",
    "\n",
    "        # BEGIN - Encoding path\n",
    "        encodeA = ConvolutionBlock(inputs, \"encodeA\", self.fms, params)\n",
    "        poolA = keras.layers.MaxPooling3D(name=\"poolA\", pool_size=(2, 2, 2))(encodeA)\n",
    "\n",
    "        encodeB = ConvolutionBlock(poolA, \"encodeB\", self.fms*2, params)\n",
    "        poolB = keras.layers.MaxPooling3D(name=\"poolB\", pool_size=(2, 2, 2))(encodeB)\n",
    "\n",
    "        encodeC = ConvolutionBlock(poolB, \"encodeC\", self.fms*4, params)\n",
    "        poolC = keras.layers.MaxPooling3D(name=\"poolC\", pool_size=(2, 2, 2))(encodeC)\n",
    "\n",
    "        encodeD = ConvolutionBlock(poolC, \"encodeD\", self.fms*8, params)\n",
    "        poolD = keras.layers.MaxPooling3D(name=\"poolD\", pool_size=(2, 2, 2))(encodeD)\n",
    "\n",
    "        encodeE = ConvolutionBlock(poolD, \"encodeE\", self.fms*16, params)\n",
    "        # END - Encoding path\n",
    "\n",
    "        # BEGIN - Decoding path\n",
    "        if self.use_upsampling:\n",
    "            up = keras.layers.UpSampling3D(name=\"upE\", size=(2, 2, 2),\n",
    "                                       interpolation=\"bilinear\")(encodeE)\n",
    "        else:\n",
    "            up = keras.layers.Conv3DTranspose(name=\"transconvE\", filters=self.fms*8,\n",
    "                                          **params_trans)(encodeE)\n",
    "        concatD = keras.layers.concatenate(\n",
    "            [up, encodeD], axis=self.concat_axis, name=\"concatD\")\n",
    "\n",
    "        decodeC = ConvolutionBlock(concatD, \"decodeC\", self.fms*8, params)\n",
    "\n",
    "        if self.use_upsampling:\n",
    "            up = keras.layers.UpSampling3D(name=\"upC\", size=(2, 2, 2),\n",
    "                                       interpolation=\"bilinear\")(decodeC)\n",
    "        else:\n",
    "            up = keras.layers.Conv3DTranspose(name=\"transconvC\", filters=self.fms*4,\n",
    "                                          **params_trans)(decodeC)\n",
    "        concatC = keras.layers.concatenate(\n",
    "            [up, encodeC], axis=self.concat_axis, name=\"concatC\")\n",
    "\n",
    "        decodeB = ConvolutionBlock(concatC, \"decodeB\", self.fms*4, params)\n",
    "\n",
    "        if self.use_upsampling:\n",
    "            up = keras.layers.UpSampling3D(name=\"upB\", size=(2, 2, 2),\n",
    "                                       interpolation=\"bilinear\")(decodeB)\n",
    "        else:\n",
    "            up = keras.layers.Conv3DTranspose(name=\"transconvB\", filters=self.fms*2,\n",
    "                                          **params_trans)(decodeB)\n",
    "        concatB = keras.layers.concatenate(\n",
    "            [up, encodeB], axis=self.concat_axis, name=\"concatB\")\n",
    "\n",
    "        decodeA = ConvolutionBlock(concatB, \"decodeA\", self.fms*2, params)\n",
    "\n",
    "        if self.use_upsampling:\n",
    "            up = keras.layers.UpSampling3D(name=\"upA\", size=(2, 2, 2),\n",
    "                                       interpolation=\"bilinear\")(decodeA)\n",
    "        else:\n",
    "            up = keras.layers.Conv3DTranspose(name=\"transconvA\", filters=self.fms,\n",
    "                                          **params_trans)(decodeA)\n",
    "        concatA = keras.layers.concatenate(\n",
    "            [up, encodeA], axis=self.concat_axis, name=\"concatA\")\n",
    "\n",
    "        # END - Decoding path\n",
    "\n",
    "        convOut = ConvolutionBlock(concatA, \"convOut\", self.fms, params)\n",
    "\n",
    "        prediction = keras.layers.Conv3D(name=\"PredictionMask\",\n",
    "                                     filters=self.n_cl_out, kernel_size=(1, 1, 1),\n",
    "                                     data_format=self.data_format,\n",
    "                                     activation=\"sigmoid\")(convOut)\n",
    "\n",
    "        model = keras.models.Model(inputs=[inputs], outputs=[prediction])\n",
    "\n",
    "        if self.print_summary:\n",
    "            model.summary()\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "    def sensitivity(self, target, prediction, axis=(1, 2, 3), smooth=0.0001):\n",
    "        \"\"\"\n",
    "        Sensitivity\n",
    "        \"\"\"\n",
    "        prediction = tf.round(prediction)\n",
    "\n",
    "        intersection = tf.reduce_sum(prediction * target, axis=axis)\n",
    "        coef = (intersection + smooth) / (tf.reduce_sum(target,\n",
    "                                                        axis=axis) + smooth)\n",
    "        return tf.reduce_mean(coef)\n",
    "\n",
    "\n",
    "    def specificity(self, target, prediction, axis=(1, 2, 3), smooth=0.0001):\n",
    "        \"\"\"\n",
    "        Specificity\n",
    "        \"\"\"\n",
    "        prediction = tf.round(prediction)\n",
    "\n",
    "        intersection = tf.reduce_sum(prediction * target, axis=axis)\n",
    "        coef = (intersection + smooth) / (tf.reduce_sum(prediction,\n",
    "                                                        axis=axis) + smooth)\n",
    "        return tf.reduce_mean(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_model = unet(use_upsampling=False,\n",
    "                  learning_rate=0.01,\n",
    "                  n_cl_in=1,\n",
    "                  n_cl_out=9,  # single channel (greyscale)\n",
    "                  feature_maps = 16,\n",
    "                  dropout=0.2,\n",
    "                  print_summary=True,\n",
    "                  channels_last = CHANNELS_LAST)  # channels first or last\n",
    "\n",
    "unet_model.model.compile(optimizer=unet_model.optimizer,\n",
    "              loss=unet_model.loss,\n",
    "              metrics=unet_model.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "log_dir = LOG_DIR + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch = '2, 20')\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "\n",
    "# Creates a file writer for the log directory.\n",
    "file_writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "# Using the file writer, log the reshaped image.\n",
    "with file_writer.as_default():\n",
    "  tf.summary.image(\"Training data\", img, step=0)\n",
    "\n",
    "\n",
    "# model checkpoint\n",
    "saved_models = sorted(glob.glob(MODELS_DIR+'*.h5'))\n",
    "initial_epoch=0\n",
    "if len(saved_models) is not 0:\n",
    "  last_epoch_name = saved_models[-1]\n",
    "  model = tf.keras.models.load_model(last_epoch_name, custom_objects=unet_model.custom_objects)\n",
    "  initial_epoch = int(str(last_epoch_name)[-9:-3])\n",
    "filepath = MODELS_DIR+\"{epoch:06d}.h5\"\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=False, save_freq=gt_len*SAVE_MODEL_PERIOD)\n",
    "\n",
    "# csv logger\n",
    "csv_logger = tf.keras.callbacks.CSVLogger(CSV_LOG_DIR, append=True)\n",
    "\n",
    "\n",
    "# Keep reducing learning rate if we get to plateau\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2,\n",
    "                                          patience=5, min_lr=0.0001)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_gt(gt, num_slices = 7):\n",
    "  # images and gts\n",
    "  coronal_gt = np.flip(gt, axis=2)\n",
    "  for lbl in range(9):\n",
    "    display(concat_h([coronal_gt[slc, :, :, lbl] for slc in range(0, coronal_gt.shape[0], coronal_gt.shape[0]//num_slices)], mode='L'))\n",
    "\n",
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    # clear_output(wait=True)\n",
    "    out = unet_model.model.predict(img)\n",
    "\n",
    "    print('out', out.shape)\n",
    "    visualize_volume(img[0, :, :, :, 0], undo_categorical(out, channels_last=True), 10)\n",
    "    visualize_gt(out[0, :, :, :, :])\n",
    "    print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))\n",
    "    \n",
    "    with file_writer.as_default():\n",
    "      tf.summary.image(\"Training data\", img, step=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = unet_model.model.fit(ds,\n",
    "        steps_per_epoch=STEP_PER_EPOCH,\n",
    "        epochs=1000, \n",
    "        callbacks=[tensorboard_callback, \n",
    "                   model_checkpoint, \n",
    "                   csv_logger, \n",
    "                   DisplayCallback(), \n",
    "                   reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_tf2",
   "language": "python",
   "name": "env_tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
